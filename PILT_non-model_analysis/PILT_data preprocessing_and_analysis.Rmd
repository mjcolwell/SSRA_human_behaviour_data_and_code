---
title: "Presentation PILT Script"
author: "Michael Colwell"
date: '2022-07-27'
output: html_document
---

## Presentation PILT pre-processing script

This script was made as an alternative to the MATLAB script for the FENCOG project by Michael Colwell (michael.colwell@psych.ox.ac.uk).

Free to use for all.

Before proceeding it is important to make sure all your files are labelled with the participant ID in the following format:

P00X
or 
p0Xx

It is robust to upper-case/lower-case letters, however if there are too many 0s it will fail to load it in.

If you have a follow-up visit, make sure the file name includes 'v2', and this will be sorted considered a follow-up or PRE visit. 

##Chunk 0: Set-up chunk

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

##Chunk 1: Loading required R packages

```{r Chunk 1 - Libraries Setup, echo=FALSE, include=FALSE}
library(dplyr)
library(tidyverse)
library(gtools)
library(knitr)
library(data.table)
library(ggplot2)
library(car)
library(ggbeeswarm)
library(ggrepel)
library(readxl)
library(data.table)
library(openxlsx)
library(ggpubr)
library(rstatix)
library("ez")
library(ggsignif)
library(RColorBrewer)
library(emmeans)
library(plotrix)
library(sdamr)
library(cowplot)
library(lme4)
library(stringr)
library(ggridges)
library(viridis)
library(stringr)
library(effectsize)
library(lmerTest)
library(ggdist)
```

#Chunk 2: Loading files into memory and creating an aggregate

```{r Chunk 2 - Loading Files, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

setwd("C:/Users/micha/Desktop/PILT_non-model_analysis")

# Create an empty data frame to store the combined data
combined_df <- data.frame()

# Get a list of all .dat files in the directory
dat_files <- list.files(pattern = "\\.dat$")

# Loop through each .dat file
for (file in dat_files) {
  # Read the file using readLines()
  lines <- readLines(file)

  # Remove the first three lines
  lines <- lines[-(1:3)]

  # Extract the file name
  file_name <- sub("\\.dat$", "", file)

  # Check if the file name contains P001, P002, etc.
  if (grepl("[Pp]\\d{3}", file_name)) {
    # Check if there are lines remaining
    if (length(lines) > 0) {
      # Replace blank spaces with NA in each line
      lines <- lapply(lines, function(line) {
        words <- strsplit(line, "\\s+")[[1]]
        words[words == ""] <- NA
        return(words)
      })

      # Find the maximum number of elements in a line
      max_elements <- max(sapply(lines, length))

      # Create a matrix to store the data
      data_matrix <- matrix(nrow = length(lines), ncol = max_elements)

      # Fill the matrix with the data from the lines
      for (i in seq_along(lines)) {
        row <- lines[[i]]
        data_matrix[i, 1:length(row)] <- row
      }

      # Convert the matrix to a data frame
      df <- as.data.frame(data_matrix, stringsAsFactors = FALSE) # Ensure strings are treated as characters

      # Add a column with the file name to the data frame
      df <- cbind(FileName = file_name, df)

      # Bind the data to the combined data frame
      combined_df <- bind_rows(combined_df, df)
    }
  }
}

# Move first row as column names
colnames(combined_df)[-1] <- combined_df[1, -1]
combined_df <- combined_df[-1, ]

# Move values from "win_out" to "loss_out" based on "trial_type"
combined_df$loss_out[combined_df$trial_type == 2] <- combined_df$win_out[combined_df$trial_type == 2]
combined_df$win_out[combined_df$trial_type == 2] <- NA

## You'll need to change this one manually##
combined_df <- rename(combined_df, file_name = FileName)

# Split 'file_name' column into 'Participant.ID' and 'Visit'
combined_df <- combined_df %>%
  mutate(
    ID <- str_extract(file_name, "(?<=^)[Pp]0*\\d+"),
    PRE.POST = ifelse(str_detect(file_name, "v2"), "POST", "PRE")
  )

# Prune 'Participant.ID' column to first few letters
combined_df$ID <- str_sub(combined_df$ID, 1, 4)

# Convert 'Participant.ID' column to uppercase
combined_df$ID <- toupper(combined_df$ID)

combined_df <- combined_df %>%
  select(ID, PRE.POST, everything())

combined_df_for_money <- combined_df

value_to_remove <- "run_number" # Specify the value to be removed
combined_df <- combined_df[!(combined_df$run_number == value_to_remove), ]

value_to_remove2 <- "Total" # Specify the value to be removed
combined_df <- combined_df[!(combined_df$run_number == value_to_remove2), ]

## Above code is duplicated intentionally.

PILT <- combined_df

## Check all the participant data is there

unique_strings <- unique(combined_df$ID)
summary <- data.frame(String = unique_strings, Count = length(unique_strings))

print(summary)

rm(data_matrix, df, lines, dat_files, file, file_name, i, max_elements, row, combined_df)
```

#Chunk Extra: DF just for amount of money won over participant

```{r Chunk 2 - Loading Files, message=FALSE, warning=FALSE, include=FALSE}
# Money value is on line 185

combined_df_for_money <- subset(combined_df_for_money, run_number == "Total")

combined_df_for_money$MoneyEarned <- as.numeric(combined_df_for_money$outcome_type)

columns_to_keep <- c("ID", "PRE.POST", "MoneyEarned")

Money_Clean <- combined_df_for_money[, columns_to_keep]

Money_Clean$PRE.POST <- recode_factor(Money_Clean$PRE.POST, "PRE" = "Baseline")
Money_Clean$PRE.POST <- recode_factor(Money_Clean$PRE.POST, "POST" = "Post")

Money_Clean_pre <- Money_Clean %>% filter(!str_detect(PRE.POST, "Post"))
Money_Clean_post <- Money_Clean %>% filter(!str_detect(PRE.POST, "Baseline"))
```

#Optional chunk: Overlapping simulated choice probabilities from fitted data.

```{r Chunk 2 - Loading Files, message=FALSE, warning=FALSE, include=FALSE}
##### Set dir first!#########
setwd("C:/Users/micha/Desktop/PILT_non-model_analysis/ModelledData_CSV_bp")
#############################

# Create file list
Choice_Prob_List <- list.files(pattern = glob2rx("*fitstruct*.csv"))

library(plyr)

# Merge files based on file list
Choice_Prob <- do.call(rbind.fill, lapply(Choice_Prob_List, function(x) read.csv(x, stringsAsFactors = FALSE)))

detach("package:plyr", unload = TRUE)

setwd("C:/Users/micha/Desktop/DemographicData")

Demographics <- read.xlsx("Demo4Analysis.xlsx")

Demographics$ID <- as.factor(Demographics$Participant.ID)

Choice_Prob <- merge(Choice_Prob, Demographics, by = "Participant.ID")

Choice_Prob <- Choice_Prob %>% rename(Loss_Prob = Var1)

Choice_Prob <- Choice_Prob %>% rename(PRE.POST = Time)

# Comment this out if you want to look at data from both timepoints

Choice_Prob <- Choice_Prob %>% filter(!str_detect(PRE.POST, "PRE"))

Choice_Prob <- subset(Choice_Prob, select = -c(Trial_type))

Choice_Prob <- subset(Choice_Prob, select = -c(trial_number))

Choice_Prob <- Choice_Prob %>%
  pivot_longer(
    cols = c(Reward_Prob, Loss_Prob),
    names_to = "trial_type",
    values_to = "ChoiceProb"
  )

Choice_Prob$ChoiceProb <- round(Choice_Prob$ChoiceProb, digits = 2)

Choice_Prob$trial_type <- recode_factor(Choice_Prob$trial_type, "Reward_Prob" = "1")
Choice_Prob$trial_type <- recode_factor(Choice_Prob$trial_type, "Loss_Prob" = "2")

Choice_Prob$trial_number <- (0:(nrow(Choice_Prob) - 1)) %% 60 + 1

# You'll need to split 'PILT' by trial_type, and also 'choice_prob'. Then make them align.

PILT_WinsOnly <- PILT %>% filter(!str_detect(trial_type, "2"))
PILT_LossesOnly <- PILT %>% filter(!str_detect(trial_type, "1"))

##
Choice_Prob_WinsOnly <- Choice_Prob %>% filter(!str_detect(trial_type, "2"))
Choice_Prob_LossOnly <- Choice_Prob %>% filter(!str_detect(trial_type, "1"))

All_wins_bound <- cbind(PILT_WinsOnly, Choice_Prob_WinsOnly)
All_loss_bound <- cbind(PILT_LossesOnly, Choice_Prob_LossOnly)

rm(PILT_WinsOnly, PILT_LossesOnly, Choice_Prob_WinsOnly, Choice_Prob_LossOnly)

###

# Simulate chance of selecting 'reward' or 'loss' option based on choice probabilities.
# Generate random numbers
random_numbers <- runif(nrow(All_wins_bound))

# Determine choices
All_wins_bound$Choice <- as.integer(All_wins_bound$ChoiceProb > runif(nrow(All_wins_bound)))

# Generate random numbers
random_numbers <- runif(nrow(All_loss_bound))

# Determine choices
All_loss_bound$Choice <- as.integer(All_loss_bound$ChoiceProb > runif(nrow(All_loss_bound)))

#### Choices around for loss trials so they are comparable with optimal choices.

All_loss_bound$Choice <- as.numeric(!All_loss_bound$Choice)
```


#Chunk 3: Initial pre-processing of data to prepare for analyses

```{r Chunk 3 - Initial Preprocessing, message=FALSE, warning=FALSE, include=FALSE}
PILT <- PILT %>% mutate(Optimal_choice = case_when((loss_out == 1) ~ "0", (loss_out == 0) ~ "1", (win_out == 1) ~ "1", (win_out == 0) ~ "0", TRUE ~ "NA"))

PILT$Optimal_choice <- as.numeric(PILT$Optimal_choice)

# RTs generation

PILT <- PILT %>% transform(RT_hits = ifelse(Optimal_choice == 1, reaction_time, NA))

PILT$reaction_time <- as.numeric(PILT$reaction_time)

# Remove response times based on the 4000ms length of time allowed for choices in the Pessiglione et al. 2006 publication)

PILT <- PILT %>% filter(reaction_time < 4000)

# Create a seperate df for the learning curve

PILT2 <- PILT

PILT2$Optimal_choice <- as.numeric(PILT2$Optimal_choice)

# Remove the first third of trials (period of learning), so you only have 20 trials per condition per run

PILT$trial_number <- as.numeric(PILT$trial_number)

PILT <- PILT %>% filter(trial_number > 19)

PILT <- PILT %>% select(-file_name)
```

#Chunk 4 (Optional): Running initial data quality tests

```{r Chunk 4 (Optional) - Initial quality checks, echo=FALSE}
# create overall summary for identifying outliers

#####

PILT_Qual_Report <- PILT %>%
  group_by(ID, PRE.POST) %>% ## Remove 'Research.Visit.Number' if not repeated-measures
  summarise(Optimal_choice = sum(Optimal_choice, na.rm = TRUE), Response.time = mean(RT_hits, na.rm = TRUE))

PILT_Qual_Report$PRE.POST <- as.factor(PILT_Qual_Report$PRE.POST)

# Generate boxplots to check for outliers (at the IQR * 1.5 range) - Modify if not repeated-measures

is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 2.0 * IQR(x) | x > quantile(x, 0.75) + 2.0 * IQR(x))
}

PILT_Qual_Report %>%
  group_by(PRE.POST) %>%
  mutate(outlier = ifelse(is_outlier(Optimal_choice), PRE.POST, as.numeric(NA))) %>%
  ggplot(aes(x = factor(PRE.POST), Optimal_choice)) +
  scale_x_discrete(limits = rev(levels(PILT_Qual_Report$PRE.POST))) +
  geom_boxplot(outlier.colour = NA) +
  ggbeeswarm::geom_beeswarm(aes(color = Optimal_choice)) +
  ggrepel::geom_text_repel(data = . %>% filter(!is.na(outlier)), aes(label = ID)) +
  scale_colour_gradient(low = "blue", high = "red") +
  labs(title = "Participant average trial outcome throughout PILT") +
  ylab("Correctness in outcome") +
  xlab("PRE or POST")

PILT_Qual_Report %>%
  group_by(PRE.POST) %>%
  mutate(outlier = ifelse(is_outlier(Response.time), PRE.POST, as.numeric(NA))) %>%
  ggplot(aes(x = factor(PRE.POST), Response.time)) +
  scale_x_discrete(limits = rev(levels(PILT_Qual_Report$PRE.POST))) +
  geom_boxplot(outlier.colour = NA) +
  ggbeeswarm::geom_beeswarm(aes(color = Response.time)) +
  ggrepel::geom_text_repel(data = . %>% filter(!is.na(outlier)), aes(label = ID)) +
  scale_colour_gradient(low = "blue", high = "red") +
  labs(title = "Participant average response time throughout PILT") +
  ylab("Response time") +
  xlab("PRE or POST")

ggplot(PILT_Qual_Report, aes(x = Response.time)) +
  geom_histogram() +
  xlab("Response time") +
  ylab("Frequency") +
  labs(title = "articipant average response time throughout PILT") +
  ylab("Response time")
```

#Chunk 5: Further preprocessing the dataframe 

```{r Chunk 5 - Further preprocessing, message=FALSE, warning=FALSE, include=FALSE}
# create overall summary for statistical analysis
# Create another non-summary to plot the curve (further down)

PILT$loss_out <- as.numeric(PILT$loss_out)
PILT$win_out <- as.numeric(PILT$win_out)
PILT$reaction_time <- as.numeric(PILT$reaction_time)
PILT$RT_hits <- as.numeric(PILT$RT_hits)

PILT_Analysis_ReportLME <- PILT %>%
  group_by(ID, PRE.POST, trial_type) %>%
  summarise(Optimal.choice = sum(Optimal_choice, na.rm = TRUE), Response.time = mean(reaction_time, na.rm = TRUE), Optimal.choice.perc = mean(Optimal_choice, na.rm = TRUE) * 100, response.time.corr = mean(RT_hits, na.rm = TRUE))

# Divide optimal choices by the total number of trials across all blocks (i.e., 40 * 3, since the first 20 trials are being excluded.)

setwd("C:/Users/micha/Desktop/DemographicData")

PILT_Analysis_ReportLME$PRE.POST <- recode_factor(PILT_Analysis_ReportLME$PRE.POST, "PRE" = "Baseline")

PILT_Analysis_ReportLME$PRE.POST <- recode_factor(PILT_Analysis_ReportLME$PRE.POST, "POST" = "Post")

PILT_Analysis_ReportLME$trial_type <- as.factor(PILT_Analysis_ReportLME$trial_type)

##

PILT_Analysis_ReportLME$trial_type <- recode_factor(PILT_Analysis_ReportLME$trial_type, "2" = "Loss trials")

PILT_Analysis_ReportLME$trial_type <- recode_factor(PILT_Analysis_ReportLME$trial_type, "1" = "Win trials")

Demographics <- read.xlsx("Demo4Analysis.xlsx")

Demographics$ID <- as.factor(Demographics$Participant.ID)

PILT_Analysis_ReportLME <- merge(PILT_Analysis_ReportLME, Demographics, by = "ID")

## Add in winstotal condition (not win or loss condition)

# Split out pre and post

PILT_Analysis_ReportPostLME <- PILT_Analysis_ReportLME %>% filter(!str_detect(PRE.POST, "Baseline"))
PILT_Analysis_ReportPreLME <- PILT_Analysis_ReportLME %>% filter(!str_detect(PRE.POST, "Post"))

## Creating and tidying curve data (CurveData and CurveData are used for creating the learning curves)

CurveData <- PILT2

CurveData$PRE.POST <- recode_factor(CurveData$PRE.POST, "PRE" = "Baseline")

CurveData$PRE.POST <- recode_factor(CurveData$PRE.POST, "POST" = "Post")

CurveData <- merge(CurveData, Demographics, by = "ID")

# Comment this out when you want to look at data from all timepoints
CurveData <- CurveData %>% filter(!str_detect(PRE.POST, "Baseline"))

CurveData <- CurveData %>% mutate(loss_out2 = case_when((loss_out == 1) ~ "1", (loss_out == 0) ~ "0", TRUE ~ "NA"))

# CurveData <- CurveData %>% mutate(loss_out2 = case_when((loss_out == 1) ~ "0", (loss_out == 0) ~ "1", TRUE ~ "NA"))

# CurveData <- CurveData %>% mutate(loss_out = case_when((loss_out == 1) ~ "0", (loss_out == 0) ~ "1", TRUE ~ "NA"))


# Change to this to make comparison with synthetic data

CurveData$loss_out2 <- as.numeric(CurveData$loss_out2)
CurveData$loss_out2 <- as.numeric(CurveData$loss_out2)
CurveData$trial_number <- as.numeric(CurveData$trial_number)
CurveData$run_number <- as.numeric(CurveData$run_number)

rm(PILT, PILT2)
```

#Chunk 6: Further parsing the curvedata

```{r Chunk 6 - Further parsing the curvedata, message=FALSE, warning=FALSE, include=FALSE}
# Initialize count variable
count <- 1

# Initialize previous run number variable
prev_run <- NULL

# Initialize output vector
output <- vector()

# Iterate over each row of the data frame
for (i in 1:nrow(CurveData)) {
  # Check if the 'run_number' has changed from the previous row
  if (!is.null(prev_run) && CurveData$run_number[i] != prev_run) {
    count <- 1
  }

  # Check if the 'trial_type' column contains the specific value (1)
  if (CurveData$trial_type[i] == 1) {
    output <- c(output, count)
    count <- count + 1
  } else {
    output <- c(output, NA)
  }

  # Update previous run number
  prev_run <- CurveData$run_number[i]
}

# Add the output vector as a new column ('win_trial_count') to the data frame
CurveData$win_trial_count <- output

###

# Initialize count variable
count <- 1

# Initialize previous run number variable
prev_run <- NULL

# Initialize output vector
output <- vector()

# Iterate over each row of the data frame
for (i in 1:nrow(CurveData)) {
  # Check if the 'run_number' has changed from the previous row
  if (!is.null(prev_run) && CurveData$run_number[i] != prev_run) {
    count <- 1
  }

  # Check if the 'trial_type' column contains the specific value (1)
  if (CurveData$trial_type[i] == 2) {
    output <- c(output, count)
    count <- count + 1
  } else {
    output <- c(output, NA)
  }

  # Update previous run number
  prev_run <- CurveData$run_number[i]
}

# Add the output vector as a new column ('loss_trial_count') to the data frame
CurveData$loss_trial_count <- output

counts2 <- table(CurveData$loss_trial_count)
counts3 <- table(CurveData$win_trial_count)

print(counts2)
print(counts3)
# Note that there appears to be slightly more win trials overall than loss trials.

rm(PILT, PILT2, count, i, output, prev_run, unique_strings, value_to_remove, value_to_remove2, summary)

## Variable conversion

CurveData$loss_out <- as.numeric(CurveData$loss_out)
CurveData$win_out <- as.numeric(CurveData$win_out)

## Now create reports and merge

WinCurveReport <- CurveData %>%
  group_by(Allocation, win_trial_count, trial_type) %>%
  summarise(Optimal.choice = mean(Optimal_choice, na.rm = TRUE) * 100, SE = sd(Optimal_choice, na.rm = TRUE) / sqrt(n()) * 100)

WinCurveReport_clean <- WinCurveReport[complete.cases(WinCurveReport), ]

names(WinCurveReport_clean)[2] <- "trial_number"

LossCurveReport <- CurveData %>%
  group_by(Allocation, loss_trial_count, trial_type) %>%
  summarise(Optimal.choice = mean(loss_out2, na.rm = TRUE) * 100, SE = sd(Optimal_choice, na.rm = TRUE) / sqrt(n()) * 100)

LossCurveReport_clean <- LossCurveReport[complete.cases(LossCurveReport), ]

names(LossCurveReport_clean)[2] <- "trial_number"

rm(LossCurveReport, WinCurveReport)

CompleteCurve <- bind_rows(WinCurveReport_clean, LossCurveReport_clean)

## Create final df for Learning Curve

CompleteCurve$Grp <- paste(CompleteCurve$Allocation, CompleteCurve$trial_type, sep = "_")

############################################

# Another curve for comparison/split

############################################

## Now create reports and merge

WinCurveReport <- CurveData %>%
  group_by(Allocation, win_trial_count, trial_type) %>%
  summarise(Optimal.choice = mean(Optimal_choice, na.rm = TRUE) * 100, SE = sd(Optimal_choice, na.rm = TRUE) / sqrt(n()) * 100)

WinCurveReport_clean <- WinCurveReport[complete.cases(WinCurveReport), ]

names(WinCurveReport_clean)[2] <- "trial_number"

LossCurveReport <- CurveData %>%
  group_by(Allocation, loss_trial_count, trial_type) %>%
  summarise(Optimal.choice = mean(loss_out2, na.rm = TRUE) * 100, SE = sd(Optimal_choice, na.rm = TRUE) / sqrt(n()) * 100)

LossCurveReport_clean <- LossCurveReport[complete.cases(LossCurveReport), ]

names(LossCurveReport_clean)[2] <- "trial_number"

rm(LossCurveReport, WinCurveReport)

CompleteCurve <- bind_rows(WinCurveReport_clean, LossCurveReport_clean)

## Create final df for Learning Curve

CompleteCurve$Grp <- paste(CompleteCurve$Allocation, CompleteCurve$trial_type, sep = "_")

############################################
```

#Chunk 6.5: Preparing model-fit curve data (probability of choice across each trial )

```{r Chunk 6 - Further parsing the curvedata, message=FALSE, warning=FALSE, include=FALSE}
# Remember to comment out the 'curvedata' above (where noted) so you can compared ALL data (PRE & POST) across simulated and real choice behaviour.

# All win bound

All_wins_bound$trial_number_real <- (0:(nrow(All_wins_bound) - 1)) %% 30 + 1

All_wins_bound$Choice <- as.numeric(All_wins_bound$Choice)

All_wins_bound_isolated <- subset(All_wins_bound, select = c("Participant.ID", "trial_number_real", "Choice", "trial_type", "run_number", "Allocation", "ChoiceProb"))

All_wins_bound_isolated <- All_wins_bound_isolated %>% rename(trial_number = trial_number_real)

All_wins_bound_isolated$Choice2 <- All_wins_bound_isolated$Choice

All_wins_bound_report <- All_wins_bound_isolated %>%
  group_by(Allocation, trial_number, trial_type) %>%
  summarise(Choice = mean(Choice, na.rm = TRUE) * 100, SE = sd(Choice2, na.rm = TRUE) / sqrt(n()) * 100)

###

All_loss_bound$trial_number_real <- (0:(nrow(All_loss_bound) - 1)) %% 30 + 1

All_loss_bound_isolated <- subset(All_loss_bound, select = c("Participant.ID", "trial_number_real", "Choice", "trial_type", "run_number", "Allocation", "ChoiceProb"))

All_loss_bound_isolated <- All_loss_bound_isolated %>% rename(trial_number = trial_number_real)

All_loss_bound_isolated$Choice2 <- All_loss_bound_isolated$Choice

All_loss_bound_report <- All_loss_bound_isolated %>%
  group_by(Allocation, trial_number, trial_type) %>%
  summarise(Choice = mean(Choice, na.rm = TRUE) * 100, SE = sd(Choice2, na.rm = TRUE) / sqrt(n()) * 100)

All_bound_final <- rbind(All_wins_bound_report, All_loss_bound_report)

rm(All_wins_bound, All_wins_bound_isolated, All_loss_bound, All_loss_bound_isolated, All_loss_bound_report, All_wins_bound_report)

All_bound_final <- All_bound_final %>%
  mutate(DataType = "Synthetic")

CompleteCurve_Com <- CompleteCurve %>%
  group_by(Allocation, trial_number, trial_type) %>%
  summarise(Choice = mean(Optimal.choice, na.rm = TRUE), SE = mean(SE, na.rm = TRUE))

CompleteCurve_Com <- CompleteCurve_Com %>%
  mutate(DataType = "Real")

All_bound_RealandSim <- rbind(CompleteCurve_Com, All_bound_final)

All_bound_RealandSim <- rbind(CompleteCurve_Com, All_bound_final)

All_bound_RealandSim <- All_bound_RealandSim %>%
  mutate(Grp = case_when(
    trial_type == 1 & Allocation == "ACTIVE" & DataType == "Real" ~ "ACTIVE_Real_1",
    trial_type == 2 & Allocation == "ACTIVE" & DataType == "Real" ~ "ACTIVE_Real_2",
    trial_type == 1 & Allocation == "PLACEBO" & DataType == "Real" ~ "PLACEBO_Real_1",
    trial_type == 1 & Allocation == "PLACEBO" & DataType == "Real" ~ "PLACEBO_Real_2",
    trial_type == 1 & Allocation == "ACTIVE" & DataType == "Synthetic" ~ "ACTIVE_Synth_1",
    trial_type == 2 & Allocation == "ACTIVE" & DataType == "Synthetic" ~ "ACTIVE_Synth_2",
    trial_type == 1 & Allocation == "PLACEBO" & DataType == "Synthetic" ~ "PLACEBO_Synth_1",
    trial_type == 1 & Allocation == "PLACEBO" & DataType == "Synthetic" ~ "PLACEBO_Synth_2",
    TRUE ~ NA_character_
  ))

###

All_bound_final <- All_bound_final %>%
  mutate(Grp = case_when(
    trial_type == 1 & Allocation == "ACTIVE" ~ "ACTIVE_1",
    trial_type == 2 & Allocation == "ACTIVE" ~ "ACTIVE_2",
    trial_type == 1 & Allocation == "PLACEBO" ~ "PLACEBO_1",
    trial_type == 2 & Allocation == "PLACEBO" ~ "PLACEBO_2",
    TRUE ~ NA_character_
  ))
```

#Chunk 7 (Optional): Generation of learning curves with synthetic data; comparison between synthetic and real data

```{r Chunk 6 - Further parsing the curvedata, message=FALSE, warning=FALSE, include=FALSE}
CurveRealvsSim <- ggplot(All_bound_final, aes(trial_number, Choice, group = Grp, colour = Allocation, linetype = Allocation)) +
  geom_segment(aes(x = 10, xend = 30, y = 50, yend = 50), linetype = "dotted", color = "azure3") +
  geom_vline(xintercept = 10, linetype = "dotted", color = "azure3") +
  geom_line() +
  geom_point(aes(shape = Allocation, linetype = NA), size = 2.75, alpha = 0.77) +
  theme_minimal() +
  geom_ribbon(aes(
    ymin = Choice - SE,
    ymax = Choice + SE, fill = Allocation
  ), color = NA, alpha = 0.11, show.legend = FALSE) +
  scale_shape_manual(values = c(19, 15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  ylab("High probability stimulus selected (%) - Synthetic Data\n") +
  xlab("Trial number\n") +
  annotate("text", x = 15, y = 60, label = "\nWin trials", size = 3.5, color = "#333333") +
  annotate("text", x = 15, y = 10, label = "\nLoss trials", size = 3.5, color = "#333333") +
  theme(text = element_text(size = 12), plot.margin = unit(c(0, 0, 0, 0), "cm"), axis.title = element_text(size = 12), legend.text = element_text(size = 10), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 10.5), legend.position = c(0.875, 0.59), legend.title = element_blank())

##

# Change density plot fill colors by groups
Optimal_Choice_Density <- ggplot(All_bound_RealandSim, aes(x = Choice, fill = DataType)) +
  geom_density(alpha = 0.4, size = 1.1) +
  geom_vline(aes(xintercept = Choice, linetype = DataType), alpha = 0.0, show.legend = TRUE) + # Add a geom for linetype legend
  theme_minimal() +
  xlab("\nOptimal Choice Selection (%)\n") +
  ylab("\nP(Density)\n") +
  theme(legend.position = "top", text = element_text(size = 14), axis.title = element_text(size = 16))


CombinedPlots1 <- plot_grid(CurveRealvsSim, Optimal_Choice_Density, align = "v", ncol = 2, labels = c("A", "B"), label_size = 20)
```



#Chunk 7.5: Generation of figures for report

```{r Chunk 7 - Generation of figures for report, echo=FALSE}
# Learning curve for publication

CurveUnified <- ggplot(CompleteCurve, aes(trial_number, Optimal.choice, group = Grp, colour = Allocation, linetype = Allocation)) +
  geom_segment(aes(x = 10, xend = 30, y = 50, yend = 50), linetype = "dotted", color = "azure3") +
  geom_vline(xintercept = 10, linetype = "dotted", color = "azure3") +
  geom_line() +
  geom_point(aes(shape = Allocation, linetype = NA), size = 2.75, alpha = 0.77) +
  geom_ribbon(aes(
    ymin = Optimal.choice - SE,
    ymax = Optimal.choice + SE, fill = Allocation
  ), color = NA, alpha = 0.11, show.legend = FALSE) +
  theme_minimal() +
  scale_shape_manual(values = c(19, 15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  ylab("High probability stimulus selected (%)\n") +
  xlab("Trial number\n") +
  annotate("text", x = 15, y = 70, label = "\nWin trials", size = 3.5, color = "#333333") +
  annotate("text", x = 15, y = 16, label = "\nLoss trials", size = 3.5, color = "#333333") +
  theme(text = element_text(size = 12), plot.margin = unit(c(0, 0, 0, 0), "cm"), axis.title = element_text(size = 12), legend.text = element_text(size = 10), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 10.5), legend.position = c(0.875, 0.59), legend.title = element_blank())

### Merge two datasets together for comparison

CompleteCurve_reward <- CompleteCurve %>% filter(!str_detect(trial_type, "2"))
CompleteCurve_loss <- CompleteCurve %>% filter(!str_detect(trial_type, "1"))

FitMod_long_curve_post_reward <- FitMod_long_curve_post %>% filter(!str_detect(trial_type, "2"))
FitMod_long_curve_post_loss <- FitMod_long_curve_post %>% filter(!str_detect(trial_type, "1"))

###



CompleteCurve_reward$Grp <- recode_factor(CompleteCurve_reward$Grp, "ACTIVE_1" = "Real")
FitMod_long_curve_post_reward$Grp <- recode_factor(FitMod_long_curve_post_reward$Grp, "ACTIVE_1" = "Synth")

CompleteCurve_reward$Grp <- recode_factor(CompleteCurve_reward$Grp, "PLACEBO_1" = "Real")
FitMod_long_curve_post_reward$Grp <- recode_factor(FitMod_long_curve_post_reward$Grp, "PLACEBO_1" = "Synth")

Combination_curve <- bind_rows(CompleteCurve_reward, FitMod_long_curve_post_reward)

Combination_curve <- Combination_curve %>%
  group_by(trial_number, Grp) %>%
  summarise(Optimal.choice = mean(Optimal.choice, na.rm = TRUE), SE = mean(SE, na.rm = TRUE))


####



CompleteCurve_loss$Grp <- recode_factor(CompleteCurve_loss$Grp, "ACTIVE_2" = "Real")
FitMod_long_curve_post_loss$Grp <- recode_factor(FitMod_long_curve_post_loss$Grp, "ACTIVE_2" = "Synth")

CompleteCurve_loss$Grp <- recode_factor(CompleteCurve_loss$Grp, "PLACEBO_2" = "Real")
FitMod_long_curve_post_loss$Grp <- recode_factor(FitMod_long_curve_post_loss$Grp, "PLACEBO_2" = "Synth")

Combination_curve2 <- bind_rows(CompleteCurve_loss, FitMod_long_curve_post_loss)

Combination_curve2 <- Combination_curve2 %>%
  group_by(trial_number, Grp) %>%
  summarise(Optimal.choice = mean(Optimal.choice, na.rm = TRUE), SE = mean(SE, na.rm = TRUE))


###

CurveUnified2 <- ggplot(Combination_curve, aes(trial_number, Optimal.choice, group = Grp, colour = Grp, linetype = Grp)) +
  geom_segment(aes(x = 10, xend = 30, y = 50, yend = 50), linetype = "dotted", color = "azure3") +
  geom_vline(xintercept = 10, linetype = "dotted", color = "azure3") +
  geom_line() +
  geom_point(aes(linetype = NA), size = 2.75, alpha = 0.77) +
  geom_ribbon(aes(
    ymin = Optimal.choice - SE,
    ymax = Optimal.choice + SE, fill = Grp
  ), color = NA, alpha = 0.11, show.legend = FALSE) +
  theme_minimal() +
  scale_shape_manual(values = c(19, 15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  ylab("Modelled choice probability vs choices - win trials\n") +
  xlab("Trial number\n") +
  theme(legend.position = "none")


CurveUnified3 <- ggplot(Combination_curve2, aes(trial_number, Optimal.choice, group = Grp, colour = Grp, linetype = Grp)) +
  geom_segment(aes(x = 10, xend = 30, y = 50, yend = 50), linetype = "dotted", color = "azure3") +
  geom_vline(xintercept = 10, linetype = "dotted", color = "azure3") +
  geom_line() +
  geom_point(aes(linetype = NA), size = 2.75, alpha = 0.77) +
  geom_ribbon(aes(
    ymin = Optimal.choice - SE,
    ymax = Optimal.choice + SE, fill = Grp
  ), color = NA, alpha = 0.11, show.legend = FALSE) +
  theme_minimal() +
  scale_shape_manual(values = c(19, 15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  ylab("Modelled choice probability vs choices - loss trials\n") +
  xlab("Trial number\n") +
  theme(legend.position = "bottom")

CombinedPlots <- plot_grid(CurveUnified2, CurveUnified3, align = "h", ncol = 2, labels = c("A", "B"))


## Boxplot for across paradigms ~ Optimal Choices %

# PILT_Analysis_ReportPostLMELoss <- PILT_Analysis_ReportPostLME %>% filter(!str_detect(trial_type, "Win trials"))

# Boxplot_All <- PILT_Analysis_ReportPostLMELoss %>% ggplot(aes(x = Allocation, y = Optimal.choice.perc, fill = Allocation)) +
#  stat_slab(
#    side = "right", scale = 0.5, show.legend = F,
#    position = position_dodge(width = .8), alpha = 0.5,
#    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
#  ) +
#  geom_boxplot(width = 0.2, outlier.shape = NA) +
#  scale_fill_brewer(palette = "Set2") +
#  scale_color_brewer(palette = "Set2") +
#  geom_signif(
#    comparisons = list(c("ACTIVE", "PLACEBO")),
#    p.adjust.method = "bonferroni",
#    map_signif_level = c("***" = 0.001, "**" = 0.01, "*" = 0.05, " " = 0.20),
#    margin_top = 0.05, textsize = 8
#  ) +
#  labs(title = " ") +
#  ylab("Optimal choices (%) - Loss trials\n") +
#  xlab(" ") +
#  theme_minimal() +
#  theme(legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), #axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_blank()) +
#  stat_boxplot(
#    geom = "errorbar",
#    width = 0.15
#  ) +
#  geom_point(position = position_jitternudge(
#    jitter.width = 0.07, jitter.height = -0.3, nudge.x = -0.3, seed = 123), aes(color = Allocation, shape = #Allocation), size = 3.25, stroke = 0.2, alpha = 0.5) +
#  scale_shape_manual(values = c(19, 15))

# Graph4 <- plot_grid(CurveUnified, PlotGraph, rel_widths = c(2, 1.0), labels = c("A", "B"))

####

Boxplot_Optimal <- PILT_Analysis_ReportPostLME %>% ggplot(aes(x = Allocation, y = Optimal.choice.perc, fill = Allocation)) +
  facet_wrap(~trial_type) +
  stat_slab(
    side = "right", scale = 0.55, show.legend = F,
    position = position_dodge(width = .8), alpha = 0.5,
    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
  ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  geom_signif(
    comparisons = list(c("ACTIVE", "PLACEBO")),
    p.adjust.method = "bonferroni",
    map_signif_level = c("***" = 0.001, "**" = 0.01, "*" = 0.05, " " = 0.20, " " = 2),
    margin_top = 0.05, textsize = 12
  ) +
  labs(title = " ") +
  ylab("Optimal choices (%)\n") +
  xlab(" ") +
  theme_minimal() +
  theme(
    legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_text(hjust = 0.41, vjust = 1, size = 14.5),
    panel.spacing = unit(-8, "lines")
  ) +
  stat_boxplot(
    geom = "errorbar",
    width = 0.15
  ) +
  geom_point(position = position_jitternudge(
    jitter.width = 0.125, jitter.height = -0.3, nudge.x = -0.265, seed = 123
  ), aes(color = Allocation, shape = Allocation), size = 4.4, stroke = 0.2, alpha = 0.5) +
  scale_shape_manual(values = c(19, 15)) +
  ylim(40, NA)

## Plot for response time across paradigms

# Boxplot_RT <- PILT_Analysis_ReportPostLMELoss %>% ggplot(aes(x = Allocation, y = Response.time, fill = #Allocation)) +
#  stat_slab(
#    side = "right", scale = 0.5, show.legend = F,
#    position = position_dodge(width = .8), alpha = 0.5,
#    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
#  ) +
#  geom_boxplot(width = 0.2, outlier.shape = NA) +
#  scale_fill_brewer(palette = "Set2") +
#  scale_color_brewer(palette = "Set2") +
#  geom_signif(
#    comparisons = list(c("ACTIVE", "PLACEBO")),
#    p.adjust.method = "bonferroni",
#    map_signif_level = c("***" = 0.001, "**" = 0.01, "**" = 0.05, " " = 0.20),
#    margin_top = 0.05, textsize = 8
#  ) +
#  labs(title = " ") +
#  ylab("Time to choice (ms) - Loss trials\n") +
#  xlab(" ") +
#  theme_minimal() +
#  theme(legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), #axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_blank()) +
#  stat_boxplot(
#    geom = "errorbar",
#    width = 0.15
#  ) +
#  geom_point(position = position_jitternudge(
#    width = 0.07, x = -0.3, seed = 123,
#    nudge.from = "jittered"
#  ), aes(color = Allocation, shape = Allocation), size = 3.25, stroke = 0.2, alpha = 0.5) +
#  scale_shape_manual(values = c(19, 15))

## I have changed to two * manually as this is what matches the EMM tests below.

Boxplot_RT <- PILT_Analysis_ReportPostLME %>% ggplot(aes(x = Allocation, y = Response.time, fill = Allocation)) +
  facet_wrap(~trial_type) +
  stat_slab(
    side = "right", scale = 0.55, show.legend = F,
    position = position_dodge(width = .8), alpha = 0.5,
    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
  ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  geom_signif(
    comparisons = list(c("ACTIVE", "PLACEBO")),
    p.adjust.method = "bonferroni",
    map_signif_level = c("***" = 0.001, "**" = 0.01, "**" = 0.05, " " = 0.20, " " = 2),
    margin_top = 0.05, textsize = 12
  ) +
  labs(title = " ") +
  ylab("Time to choice (ms)\n") +
  xlab(" ") +
  theme_minimal() +
  theme(
    legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_text(hjust = 0.41, vjust = 1, size = 14.5),
    panel.spacing = unit(-8, "lines")
  ) +
  stat_boxplot(
    geom = "errorbar",
    width = 0.15
  ) +
  geom_point(position = position_jitternudge(
    jitter.width = 0.125, jitter.height = -0.3, nudge.x = -0.265, seed = 123
  ), aes(color = Allocation, shape = Allocation), size = 4.4, stroke = 0.2, alpha = 0.5) +
  scale_shape_manual(values = c(19, 15)) +
  ylim(40, NA)

## Baseline data

# Optimal choices

Boxplot_Optimal_pre <- PILT_Analysis_ReportPreLME %>% ggplot(aes(x = Allocation, y = Optimal.choice.perc, fill = Allocation)) +
  facet_wrap(~trial_type) +
  stat_slab(
    side = "right", scale = 0.55, show.legend = F,
    position = position_dodge(width = .8), alpha = 0.5,
    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
  ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  geom_signif(
    comparisons = list(c("ACTIVE", "PLACEBO")),
    p.adjust.method = "bonferroni",
    map_signif_level = c("***" = 0.001, "**" = 0.01, "*" = 0.05, " " = 0.20, " " = 2),
    margin_top = 0.05, textsize = 12
  ) +
  labs(title = " ") +
  ylab("Optimal choices (%)\n") +
  xlab(" ") +
  theme_minimal() +
  theme(
    legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_text(hjust = 0.41, vjust = 1, size = 14.5),
    panel.spacing = unit(-8, "lines")
  ) +
  stat_boxplot(
    geom = "errorbar",
    width = 0.15
  ) +
  geom_point(position = position_jitternudge(
    jitter.width = 0.125, jitter.height = -0.3, nudge.x = -0.265, seed = 123
  ), aes(color = Allocation, shape = Allocation), size = 4.4, stroke = 0.2, alpha = 0.5) +
  scale_shape_manual(values = c(19, 15)) +
  ylim(40, NA)

# Response time

Boxplot_RT <- PILT_Analysis_ReportPreLME %>% ggplot(aes(x = Allocation, y = Response.time, fill = Allocation)) +
  facet_wrap(~trial_type) +
  stat_slab(
    side = "right", scale = 0.55, show.legend = F,
    position = position_dodge(width = .8), alpha = 0.5,
    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
  ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  geom_signif(
    comparisons = list(c("ACTIVE", "PLACEBO")),
    p.adjust.method = "bonferroni",
    map_signif_level = c("***" = 0.001, "**" = 0.01, "**" = 0.05, " " = 0.20, " " = 2),
    margin_top = 0.05, textsize = 12
  ) +
  labs(title = " ") +
  ylab("Time to choice (ms)\n") +
  xlab(" ") +
  theme_minimal() +
  theme(
    legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_text(hjust = 0.41, vjust = 1, size = 14.5),
    panel.spacing = unit(-8, "lines")
  ) +
  stat_boxplot(
    geom = "errorbar",
    width = 0.15
  ) +
  geom_point(position = position_jitternudge(
    jitter.width = 0.125, jitter.height = -0.3, nudge.x = -0.265, seed = 123
  ), aes(color = Allocation, shape = Allocation), size = 4.4, stroke = 0.2, alpha = 0.5) +
  scale_shape_manual(values = c(19, 15)) +
  ylim(40, NA)


# PlotGraphRTCurve <- PILT_Analysis_ReportPostLMELoss %>%
#  group_by(Allocation) %>%
#  ggplot(aes(x = Response.time, y = Allocation, fill = ..x..)) +
#  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
#      scale_fill_viridis(name = "Response time", option = "F", alpha = 0.98) +
#    ylab("Response density\n\n") +
#  xlab("Time to choice (ms) - Loss trials\n\n") +
#  theme_minimal()+
#  theme(legend.position="none")+
#  xlim(0,2750)+
#  geom_segment(aes(x = 2650, y = 1, xend = 2650, yend = 2, group = "segment"))+
#  geom_segment(aes(x = 2650, y = 1, xend = 2625, yend = 1, group = "segment")) +
#  geom_segment(aes(x = 2650, y = 2, xend = 2625, yend = 2, group = "segment"))+
#  geom_text(aes(x = 2700, label = "*", y = 1.45), colour = "Black", size = 6.2)+
#  geom_text(aes(x = 2700, label = "*", y = 1.55), colour = "Black", size = 6.2)

## Money Graph

Boxplot_Money_Post <- Money_Clean_post %>% ggplot(aes(x = Allocation, y = MoneyEarned, fill = Allocation)) +
  stat_slab(
    side = "right", scale = 0.55, show.legend = F,
    position = position_dodge(width = .8), alpha = 0.5,
    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
  ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  geom_signif(
    comparisons = list(c("ACTIVE", "PLACEBO")),
    p.adjust.method = "bonferroni",
    map_signif_level = c("***" = 0.001, "**" = 0.01, "**" = 0.05, " " = 0.20, " " = 2),
    margin_top = 0.05, textsize = 12
  ) +
  labs(title = " ") +
  ylab("Total Money Earned (£)\n") +
  xlab(" ") +
  theme_minimal() +
  theme(
    legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_text(hjust = 0.41, vjust = 1, size = 14.5),
    panel.spacing = unit(-8, "lines")
  ) +
  stat_boxplot(
    geom = "errorbar",
    width = 0.15
  ) +
  geom_point(position = position_jitternudge(
    jitter.width = 0.125, jitter.height = -0.3, nudge.x = -0.265, seed = 123
  ), aes(color = Allocation, shape = Allocation), size = 4.4, stroke = 0.2, alpha = 0.5) +
  scale_shape_manual(values = c(19, 15))

Boxplot_Money_Pre <- Money_Clean_pre %>% ggplot(aes(x = Allocation, y = MoneyEarned, fill = Allocation)) +
  stat_slab(
    side = "right", scale = 0.55, show.legend = F,
    position = position_dodge(width = .8), alpha = 0.5,
    aes(fill_ramp = stat(level)), .width = c(.50, .95, 1)
  ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  geom_signif(
    comparisons = list(c("ACTIVE", "PLACEBO")),
    p.adjust.method = "bonferroni",
    map_signif_level = c("***" = 0.001, "**" = 0.01, "**" = 0.05, " " = 0.20, " " = 2),
    margin_top = 0.05, textsize = 12
  ) +
  labs(title = " ") +
  ylab("Total Money Earned (£)\n") +
  xlab(" ") +
  theme_minimal() +
  theme(
    legend.position = "none", text = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 20), axis.text.x = element_text(size = 14), strip.text = element_text(hjust = 0.41, vjust = 1, size = 14.5),
    panel.spacing = unit(-8, "lines")
  ) +
  stat_boxplot(
    geom = "errorbar",
    width = 0.15
  ) +
  geom_point(position = position_jitternudge(
    jitter.width = 0.125, jitter.height = -0.3, nudge.x = -0.265, seed = 123
  ), aes(color = Allocation, shape = Allocation), size = 4.4, stroke = 0.2, alpha = 0.5) +
  scale_shape_manual(values = c(19, 15))

CombinedPlots <- plot_grid(Boxplot_Money_Pre, Boxplot_Money_Post, align = "h", ncol = 2, labels = c("A", "B"))

##
```

#Chunk 8: ANCOVA-type LME inferrential analyses, emmeans and descriptive stats

```{r Chunk 8 - ANCOVA-type LME inferrential analyses, emmeans and descriptive stats, echo=FALSE}
# Generating models with pre regressors

#

ANCOdf1 <- PILT_Analysis_ReportPostLME[c("Allocation", "Participant.ID", "Optimal.choice", "Response.time", "trial_type", "Gender")]

ANCOdf1 <- rename(ANCOdf1, Optimal_choice_Post = Optimal.choice)
ANCOdf1 <- rename(ANCOdf1, RTPost = Response.time)

ANCOdf2 <- PILT_Analysis_ReportPreLME[c("Allocation", "Participant.ID", "Optimal.choice", "Response.time", "trial_type", "Gender")]

ANCOdf2 <- rename(ANCOdf2, Optimal_choice_Pre = Optimal.choice)
ANCOdf2 <- rename(ANCOdf2, RTPre = Response.time)

ANCOdfcomp <- left_join(ANCOdf1, ANCOdf2, by = c("Participant.ID", "Allocation", "trial_type", "Gender"))

## Optimal choice analysis

ANCOVA_Post_Optimal <- aov(Optimal_choice_Post ~ Allocation + trial_type + Allocation:trial_type + Optimal_choice_Pre + Error(Participant.ID), data = ANCOdfcomp)

summary(ANCOVA_Post_Optimal)

model_linear <- lmer(Optimal_choice_Post ~ Allocation + trial_type + Allocation:trial_type + Optimal_choice_Pre + (1 | Participant.ID), data = ANCOdfcomp)

eta_squared(model_linear, ci = 0.95, alternative = "two.sided")

# Significant effect - proceed to analysing post data as post hoc

# Calculate estimated marginal means (EMMs) for Allocation*Condition interaction
model_linear <- lm(Optimal_choice_Post ~ Allocation + trial_type + Allocation:trial_type, data = ANCOdfcomp)
EMM_2 <- emmeans(model_linear, ~ Allocation | trial_type)

# Calculate pairwise comparisons for the specified contrasts
pairwise_comparisons <- pairs(EMM_2, adjust = "holm")

# Print the results
summary(pairwise_comparisons)

# Calculate effect size using eff_size
effect_size <- eff_size(EMM_2, sigma = sigma(model_linear), edf = df.residual(model_linear))

# Print the effect size summary
summary(effect_size)

# Descriptive stats

ANCOdf1 %>%
  group_by(Trial_type, Allocation) %>%
  get_summary_stats(Optimal_choice_Post, type = "mean_sd")

# Gender analysis

ANCOVA_Post_RT <- aov(Optimal_choice_Post ~ Allocation + trial_type + Allocation * trial_type + Gender + Gender:Allocation + Gender:Allocation:trial_type + Optimal_choice_Pre + Error(Participant.ID), data = ANCOdfcomp)

summary(ANCOVA_Post_RT)

ANCOdf1 %>%
  group_by(Gender, Allocation) %>%
  get_summary_stats(Optimal_choice_Post, type = "mean_sd")

#### Mixed effects ANCOVA - RT

ANCOVA_Post_RT <- aov(RTPost ~ Allocation + trial_type + RTPre + Allocation:trial_type + Error(Participant.ID), data = ANCOdfcomp)

summary(ANCOVA_Post_RT)

model_linear <- lmer(RTPost ~ Allocation + trial_type + Allocation:trial_type + RTPre + (1 | Participant.ID), data = ANCOdfcomp)

eta_squared(model_linear, ci = 0.95, alternative = "two.sided")

# Significant effect - proceed to post-hoc and effect size calculation.

# Calculate estimated marginal means (EMMs) for Allocation*Condition interaction
model_linear <- lm(RTPost ~ Allocation + trial_type + Allocation:trial_type, data = ANCOdfcomp)
EMM_2 <- emmeans(model_linear, ~ Allocation | trial_type)

# Calculate pairwise comparisons for the specified contrasts
pairwise_comparisons <- pairs(EMM_2, adjust = "holm")

# Print the results
summary(pairwise_comparisons)

# Calculate effect size using eff_size
effect_size <- eff_size(EMM_2, sigma = sigma(model_linear), edf = df.residual(model_linear))

# Print the effect size summary
summary(effect_size)


# Descriptive stats

ANCOdf1 %>%
  group_by(Trial_type, Allocation) %>%
  get_summary_stats(RTPost, type = "mean_sd")

# Gender analysis

ANCOVA_Post_RT <- aov(RTPost ~ Allocation + trial_type + Allocation * trial_type + Gender + Gender:Allocation + Gender:Allocation:trial_type + RTPre + Error(Participant.ID), data = ANCOdfcomp)

summary(ANCOVA_Post_RT)

ANCOdf1 %>%
  group_by(Gender, Allocation) %>%
  get_summary_stats(RTPost, type = "mean_sd")

#######

#Sensitivity Analysis following Review #2
#Equivalence tests

library(TOSTER)
#Checking between-groups equivalence for optimal choices during reward trials
TOSTtwo(m1=48.385,m2=47.704,sd1=13.423,sd2=11.374,n1=26,n2=27,low_eqbound=-0.69, high_eqbound=0.69, alpha = 0.05, var.equal=TRUE)

#Checking between-groups equivalence for response times during reward trials
TOSTtwo(m1=856.013,m2=842.04,sd1=257.478,sd2=267.344,n1=26,n2=27,low_eqbound=-0.69, high_eqbound=0.69, alpha = 0.05, var.equal=TRUE)

#######

### Money analysis

Money_Clean_post <- merge(Money_Clean_post, Demographics, by = "ID")
Money_Clean_pre <- merge(Money_Clean_pre, Demographics, by = "ID")

ANCOdf1 <- Money_Clean_post[c("Allocation", "ID", "MoneyEarned", "Gender")]

ANCOdf1 <- rename(ANCOdf1, MoneyEarned_Post = MoneyEarned)

ANCOdf2 <- Money_Clean_pre[c("Allocation", "ID", "MoneyEarned", "Gender")]

ANCOdf2 <- rename(ANCOdf2, MoneyEarned_Pre = MoneyEarned)

ANCOdfcomp <- left_join(ANCOdf1, ANCOdf2, by = c("ID", "Allocation", "Gender"))

#####

ANCOVA_Post_Money <- aov(MoneyEarned_Post ~ Allocation + MoneyEarned_Pre + Error(ID), data = ANCOdfcomp)

summary(ANCOVA_Post_Money)

ANCOdfcomp %>%
  group_by(Allocation) %>%
  get_summary_stats(MoneyEarned_Post, type = "mean_sd")

#####

# Gender analysis

ANCOVA_Post_Money <- aov(MoneyEarned_Post ~ Allocation + MoneyEarned_Pre + Gender + Gender:Allocation + Error(ID), data = ANCOdfcomp)

summary(ANCOVA_Post_Money)

ANCOdfcomp %>%
  group_by(Allocation, Gender) %>%
  get_summary_stats(MoneyEarned_Post, type = "mean_sd")


## Scatterplot

ANCOdfcomp2 <- ANCOdfcomp

ANCOdfcomp2 <- ANCOdfcomp2 %>% filter(!str_detect(trial_type, "Win trials"))

scatterplot_example <- ggplot(data = ANCOdfcomp2, aes(x = Optimal_choice_Post, y = Optimal_choice_Pre, color = Allocation)) +
  geom_point(aes(shape = Allocation), size = 4, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  labs(
    title = "",
    x = "Follow-up (Optimal Choice Post)",
    y = "Baseline (Optimal Choice Pre)"
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme_minimal()

##

# Fit ANCOVA model
ancova_model <- lm(Optimal_choice_Post ~ Allocation + Optimal_choice_Pre, data = ANCOdfcomp2)

# Add predicted values to the data frame
ANCOdfcomp2$Adjusted_Optimal_choice_Post <- predict(ancova_model)

# Visualize the adjusted scores
adjusted_scatterplot <- ggplot(data = ANCOdfcomp2, aes(x = Optimal_choice_Pre, y = Adjusted_Optimal_choice_Post, color = Allocation)) +
  geom_point(aes(shape = Allocation), size = 4, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  labs(
    title = "Adjusted Follow-up Scores After ANCOVA",
    x = "Baseline (Optimal Choice Pre)",
    y = "Adjusted Follow-up (Optimal Choice Post)"
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme_minimal()
```


#Chunk 9: Depreciated code

```{r Chunk 8 - ANCOVA-type LME inferrential analyses, emmeans and descriptive stats, echo=FALSE}
# Depreciated ANOVA:
# ancova_model <- aov(Optimal_choice_Post ~ Allocation + trial_type + Optimal_choice_Pre + Allocation:trial_type, data = ANCOdfcomp)

# PILT_LMER <- lmer(RTPost ~ Allocation + trial_type + RTPre + Allocation:trial_type + (1 | Participant.ID), data = ANCOdfcomp)
# confint(PILT_LMER)
# anova(PILT_LMER, ddf = "Kenward-Roger")
# ANCOVA_Pre_Optimal <- aov(Optimal_choice_Pre ~ Allocation + trial_type + Error(Participant.ID), data = ANCOdfcomp)
# summary(ANCOVA_Pre_Optimal)
# ANCOVA_Pre_RT <- aov(RTPre ~ Allocation + trial_type + Error(Participant.ID), data = ANCOdfcomp)
# summary(ANCOVA_Pre_RT)

# Depreciated learning curve:

CurveUnified <- CurveData %>%
  group_by(trial_number, run_number, Allocation) %>%
  summarize(value = mean(win_out, na.rm = TRUE) * 100, value2 = mean(loss_out, na.rm = TRUE) * 100) %>%
  ggplot(aes(T, value, group = Allocation)) +
  scale_color_brewer(palette = "Set2") +
  stat_smooth(aes(x = trial_number, y = value, color = Allocation, linetype = Allocation),
    method = "lm",
    formula = y ~ poly(x, 21), se = FALSE, show_guide = FALSE, size = 0.6, alpha = 0.15
  ) +
  stat_smooth(aes(x = trial_number, y = value2, color = Allocation, linetype = Allocation),
    method = "lm",
    formula = y ~ poly(x, 21), se = FALSE, show_guide = TRUE, size = 0.6, alpha = 0.15
  ) +
  labs(title = "") +
  ylab("High probability stimulus selected (%)\n") +
  xlab("Trial number") +
  theme_minimal() +
  theme(text = element_text(size = 12), legend.position = "right", plot.margin = unit(c(0, 0, 0, 0), "cm"), axis.title = element_text(size = 12), legend.text = element_text(size = 10), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 10.5)) +
  geom_hline(yintercept = 50, linetype = "dashed", color = "grey") +
  geom_vline(xintercept = 20, linetype = "dashed", color = "grey") +
  annotate("text", x = 30, y = 70, label = "\nHigh probability win", size = 3.5, color = "#333333") +
  annotate("text", x = 30, y = 15, label = "\nHigh probability loss", size = 3.5, color = "#333333")
```

```{r Chunk 9 - Extra checks, echo=FALSE}
# Checking Go Fear trials RT (AGNG) vs loss learning (optimal choices)

CorrDF <- read.csv("C:/Users/micha/Desktop/EGNG_non-model_analysis/Extra/Fear Go RTs corr Loss Optimal_DrugOnly.csv", header = TRUE, stringsAsFactors = FALSE)

Scatter_check <- ggplot(CorrDF, aes(x = GoRTmeanPost, y = Optimal_choice_Post)) +
  geom_point(size = 3, alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "black") + # Add a linear regression line
  geom_text(
    aes(
      x = max(CorrDF$GoRTmeanPost), y = max(CorrDF$Optimal_choice_Post),
      label = paste("R =", round(cor(CorrDF$GoRTmeanPost, CorrDF$Optimal_choice_Post), 3))
    ),
    hjust = 1, vjust = 1, size = 4, color = "black"
  ) + # Add R value as text

  # Customize the plot further as needed
  labs(
    title = " ",
    x = "\n\n Response time for 'Go' trials (aversive faces)",
    y = "\n Optimal choices (loss trials)"
  ) +
  theme_minimal() +
  theme(legend.position = "none", text = element_text(size = 14), strip.text = element_blank(), axis.title.x = element_text(size = 15), axis.title.y = element_text(size = 15))

###

# Generating simulated data
set.seed(123)
n <- 100
baseline <- rnorm(n, mean = 50, sd = 10)
learning_effects <- rnorm(n, mean = 5, sd = 3)
intervention_effect <- rnorm(n, mean = 7, sd = 3)

group_A_followup <- baseline + learning_effects + intervention_effect
group_B_followup <- baseline + learning_effects

df <- data.frame(
  Group = rep(c("A", "B"), each = n),
  Baseline = rep(baseline, times = 2),
  Followup = c(group_A_followup, group_B_followup)
)

# Visualizing the data
library(ggplot2)

ggplot(data = df, aes(x = Baseline, y = Followup, color = Group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = "Simulated Data with Learning and Treatment Effects",
    x = "Baseline",
    y = "Follow-up"
  ) +
  theme_minimal()

# Fitting ANCOVA model
ancova_model <- lm(Followup ~ Group + Baseline, data = df)

# Adding predicted values to the data frame
df$Adjusted_Followup <- predict(ancova_model)

# Visualizing the adjusted scores
test <- ggplot(data = df, aes(x = Baseline, y = Adjusted_Followup, color = Group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = "Adjusted Follow-up Scores After ANCOVA",
    x = "Baseline",
    y = "Adjusted Follow-up"
  ) +
  theme_minimal()
```
